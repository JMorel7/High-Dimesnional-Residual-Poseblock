1. train base network: CUDA_VISIBLE_DEVICES=0 python predict_3dpose.py --camera_frame --residual --batch_norm --dropout 0.5 --max_norm --evaluateActionWise --use_sh
2. add grammar model: CUDA_VISIBLE_DEVICES=0 python predict_3dpose.py --camera_frame --residual --batch_norm --dropout 0.5 --max_norm --evaluateActionWise --use_sh --load 4874200 --add_grammar --learning_rate 1e-5
3. if you need to use extra data to train or use protocol #3, modify the function create_2d_data() in src/data_utils.py
4. to generate atomic pose and gmm for each atomic pose, run python src/cluster.py
5. to run on your own data, first generate 2d pose detection results using Stacked Hourglass or RMPE, then link the .h5 output under data/h36m/, then run CUDA_VISIBLE_DEVICES=0 python src/predict_3dpose_demo.py --residual --batch_norm --dropout 0.5 --max_norm --evaluateActionWise --use_sh --load 97485 --add_grammar

  H36M_NAMES[0] = 'RHip'
  H36M_NAMES[1] = 'RKnee'
  H36M_NAMES[2] = 'RFoot'
  H36M_NAMES[3] = 'LHip'
  H36M_NAMES[4] = 'LKnee'
  H36M_NAMES[5] = 'LFoot'
  H36M_NAMES[6] = 'Spine'
  H36M_NAMES[7] = 'Thorax'
  H36M_NAMES[8] = 'Neck/Nose'
  H36M_NAMES[9] = 'Head'
  H36M_NAMES[10] = 'LShoulder'
  H36M_NAMES[11] = 'LElbow'
  H36M_NAMES[12] = 'LWrist'
  H36M_NAMES[13] = 'RShoulder'
  H36M_NAMES[14] = 'RElbow'
  H36M_NAMES[15] = 'RWrist'

python predict_3dpose.py --camera_frame --residual --batch_norm --dropout 0.5 --max_norm --evaluateActionWise --use_sh --load 4313667 --add_grammar --learning_rate 1e-4